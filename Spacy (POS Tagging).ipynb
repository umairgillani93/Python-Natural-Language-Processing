{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts of Speech Tagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"The quick brown fox jumped over the lazy dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Th quick brown fox jumped over the lazy dog\n"
     ]
    }
   ],
   "source": [
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "print(doc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumped\n"
     ]
    }
   ],
   "source": [
    "print(doc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n",
      "ADP\n"
     ]
    }
   ],
   "source": [
    "# now we can grab the various attributes of the token tags, like\n",
    "\n",
    "print(doc[5].text)\n",
    "print(doc[5].pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN\n"
     ]
    }
   ],
   "source": [
    "print(doc[5].tag_) # reports back the fine grained tag of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT\n"
     ]
    }
   ],
   "source": [
    "print(doc[6].tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1292078113972184607\n"
     ]
    }
   ],
   "source": [
    "print(doc[5].tag) # if we just call 'tag' attribute, it's going\n",
    "# to report back the numerical id corresponding to that thag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "# and same the POS as well\n",
    "print(doc[5].pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "print(doc[4].pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The        DET        DT         determiner\n",
      "quick      ADJ        JJ         adjective\n",
      "brown      ADJ        JJ         adjective\n",
      "fox        NOUN       NN         noun, singular or mass\n",
      "jumped     VERB       VBD        verb, past tense\n",
      "over       ADP        IN         conjunction, subordinating or preposition\n",
      "the        DET        DT         determiner\n",
      "lazy       ADJ        JJ         adjective\n",
      "dog        NOUN       NN         noun, singular or mass\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text:{10}} {token.pos_:{10}} {token.tag_:{10}} {spacy.explain(token.tag_)}\") # spacy.explain() -> explains what token.tag_ means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cool :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(u\"I read books on NLP\")\n",
    "\n",
    "word = doc1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read\n"
     ]
    }
   ],
   "source": [
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read       VERB       VBP        verb, non-3rd person singular present\n"
     ]
    }
   ],
   "source": [
    "token = word\n",
    "print(f\"{token.text:{10}} {token.pos_:{10}} {token.tag_:{10}} {spacy.explain(token.tag_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read       VERB       VBD        verb, past tense\n"
     ]
    }
   ],
   "source": [
    "# consider another example!\n",
    "\n",
    "doc2 = nlp(u\"I read a book on NLP\")\n",
    "\n",
    "word = doc2[1]\n",
    "token = word\n",
    "print(f\"{token.text:{10}} {token.pos_:{10}} {token.tag_:{10}} {spacy.explain(token.tag_)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now in above both examples, notice the difference that, spacy is smart enough to understand the contextual\n",
    "# difference between two sentences. The word is exactly the same in both cases but due to the contextual meaninngs\n",
    "# spacy is referring different explanations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{83: 3, 99: 1, 84: 1, 89: 2, 91: 2}\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"The quick brown fox jumped over the lazy dog\")\n",
    "\n",
    "POS_counts = doc.count_by(spacy.attrs.POS)\n",
    "\n",
    "print(POS_counts) # reports back the frequency of the POS numerical id's in context\n",
    "\n",
    "# Now let's go ahead and grab the actual POS tag for the numerical id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[3].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83. ADJ   3\n",
      "84. ADP   1\n",
      "89. DET   2\n",
      "91. NOUN  2\n",
      "99. VERB  1\n"
     ]
    }
   ],
   "source": [
    "for k,v in sorted(POS_counts.items()):\n",
    "    print(f\"{k}. {doc.vocab[k].text:{5}} {v}\") # reports back the text for every key inside our POS_count dictionary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1292078113972184607. IN    1\n",
      "10554686591937588953. JJ    3\n",
      "15267657372422890137. DT    2\n",
      "15308085513773655218. NN    2\n",
      "17109001835818727656. VBD   1\n"
     ]
    }
   ],
   "source": [
    "# Now let's do it for the 'fine-grained tags' as well!\n",
    "TAG_counts = doc.count_by(spacy.attrs.TAG)\n",
    "\n",
    "for k,v in sorted(TAG_counts.items()):\n",
    "    print(f\"{k}. {doc.vocab[k].text:{5}} {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399. amod  3\n",
      "412. det   2\n",
      "426. nsubj 1\n",
      "436. pobj  1\n",
      "440. prep  1\n",
      "8206900633647566924. ROOT  1\n"
     ]
    }
   ],
   "source": [
    "# Now let's finally count the syntactic dependencies in our doc:\n",
    "\n",
    "DEP_counts = doc.count_by(spacy.attrs.DEP)\n",
    "\n",
    "for k,v in sorted(DEP_counts.items()):\n",
    "    print(f\"{k}. {doc.vocab[k].text:{5}} {v}\")\n",
    "\n",
    "# Less common ones are having larger number associated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
