{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary Matching with Spacy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm') # loading the English library we download earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we are gonna do the following things:\n",
    "\n",
    "# rule based matching\n",
    "# create library of token patterns\n",
    "# match those token patterns against a doc object to return a list of found matches\n",
    "# a similar type of idea to regular expression \n",
    "\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets go ahead and detech the patterns\n",
    "# SolarPower\n",
    "# solar-power\n",
    "# solar power\n",
    "\n",
    "pattern1 = [{'LOWER': 'solarpower'}] # convert the word into all lower letters and check if it matches with\n",
    "# some pattern 'solarpower'\n",
    "\n",
    "# Is there any pattern with all lower case --> 'solar'\n",
    "# Is it punctuated --> True / False\n",
    "# Is there any pattern with all lower case --> 'power'\n",
    "pattern2 = [{'LOWER':'solar'},{'IS_PUNCT': True}, {'LOWER':'power'}]\n",
    "\n",
    "pattern3 = [{'LOWER':'solar'},{},{'LOWER':'power'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('SolarPower', None, pattern1, pattern2, pattern3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"The solarpower industy continues to grow as the Solar power increases. Solar-power is amazing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 2), (8656102463236116519, 12, 15), (8656102463236116519, 12, 15)]\n"
     ]
    }
   ],
   "source": [
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8656102463236116519 SolarPower 1 2 solarpower\n",
      "8656102463236116519 SolarPower 12 15 Solar-power\n",
      "8656102463236116519 SolarPower 12 15 Solar-power\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id] # get string representation\n",
    "    span = doc[start:end] # get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.remove('SolarPower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 2), (8656102463236116519, 12, 15), (8656102463236116519, 12, 15)]\n"
     ]
    }
   ],
   "source": [
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows the pattern to matche zero or more times\n",
    "\n",
    "pattern1_new = [{'LOWER': 'solarpower'}] \n",
    "\n",
    "pattern2_new = [{'LOWER':'solar'},{'IS_PUNCT': True, 'OP':'*'}, {'LOWER':'power'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('SolarPower', None, pattern1_new, pattern2_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"solar power is solar-power yey!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches1 = matcher(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8656102463236116519, 1, 2),\n",
       " (8656102463236116519, 12, 15),\n",
       " (8656102463236116519, 12, 15)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8656102463236116519 SolarPower 1 2 solarpower\n",
      "8656102463236116519 SolarPower 12 15 Solar-power\n",
      "8656102463236116519 SolarPower 12 15 Solar-power\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id] # get string representation\n",
    "    span = doc[start:end] # get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase Matching with Spacy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher1 = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('https://en.wikipedia.org/wiki/Reaganomics') as file:\n",
    "    doc3 = nlp(file.read())\n",
    "    \n",
    "# let's go ahead and declare a list of phrases. These are the phrases we'll be searching\n",
    "phrase_list = ['voodoo economics', 'supply-side economics', 'trickle-down economics', 'free-market economics']\n",
    "\n",
    "# lets now associated each Phrase to a document object. # This reports back the bunch of docs in Phrase patterns\n",
    "phrase_patterns = [nlp(text) for text in phrase_list]\n",
    "\n",
    "# lets now pass each 'doc' object into the matcher. And pass each token (phrase_pattern) as a keyword arguments\n",
    "matcher.add('EconMatcher', None, *phrase_pattern) # grabs each phrase_pattern token and passes it individually to matcher.add() method\n",
    "\n",
    "found_matches = matcher(doc3)\n",
    "\n",
    "print(found_matches)\n",
    "\n",
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id] # get string representation\n",
    "    span = doc3[start:end] # get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)\n",
    "\n",
    "\n",
    "# That's how we can create a list of Phrases to match on\n",
    "\n",
    "# What if we want to grab the context of the document\n",
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id] # get string representation\n",
    "    span = doc3[start - 5 :end + 5] # Just start -5 tokens back and end +5 token ahead\n",
    "    print(match_id, string_id, start, end, span.text)\n",
    "\n",
    "# And now it's gonna essentially report back all the sentences which lie in context!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
